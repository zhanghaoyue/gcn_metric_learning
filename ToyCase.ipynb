{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "pycharm": {
          "is_executing": false
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "We have 34 nodes.\nWe have 156 edges.\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "import dgl\n\ndef build_karate_club_graph():\n    g \u003d dgl.DGLGraph()\n    # add 34 nodes into the graph; nodes are labeled from 0~33\n    g.add_nodes(34)\n    # all 78 edges as a list of tuples\n    edge_list \u003d [(1, 0), (2, 0), (2, 1), (3, 0), (3, 1), (3, 2),\n        (4, 0), (5, 0), (6, 0), (6, 4), (6, 5), (7, 0), (7, 1),\n        (7, 2), (7, 3), (8, 0), (8, 2), (9, 2), (10, 0), (10, 4),\n        (10, 5), (11, 0), (12, 0), (12, 3), (13, 0), (13, 1), (13, 2),\n        (13, 3), (16, 5), (16, 6), (17, 0), (17, 1), (19, 0), (19, 1),\n        (21, 0), (21, 1), (25, 23), (25, 24), (27, 2), (27, 23),\n        (27, 24), (28, 2), (29, 23), (29, 26), (30, 1), (30, 8),\n        (31, 0), (31, 24), (31, 25), (31, 28), (32, 2), (32, 8),\n        (32, 14), (32, 15), (32, 18), (32, 20), (32, 22), (32, 23),\n        (32, 29), (32, 30), (32, 31), (33, 8), (33, 9), (33, 13),\n        (33, 14), (33, 15), (33, 18), (33, 19), (33, 20), (33, 22),\n        (33, 23), (33, 26), (33, 27), (33, 28), (33, 29), (33, 30),\n        (33, 31), (33, 32)]\n    # add edges two lists of nodes: src and dst\n    src, dst \u003d tuple(zip(*edge_list))\n    g.add_edges(src, dst)\n    # edges are directional in DGL; make them bi-directional\n    g.add_edges(dst, src)\n\n    return g\n\nG \u003d build_karate_club_graph()\nprint(\u0027We have %d nodes.\u0027 % G.number_of_nodes())\nprint(\u0027We have %d edges.\u0027 % G.number_of_edges())"
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "outputs": [],
      "source": "\nimport networkx as nx\n# Since the actual graph is undirected, we convert it for visualization\n# purpose.\nnx_G \u003d G.to_networkx().to_undirected()\n# Kamada-Kawaii layout usually looks pretty for arbitrary graphs\npos \u003d nx.kamada_kawai_layout(nx_G)\nnx.draw(nx_G, pos, with_labels\u003dTrue, node_color\u003d[[.7, .7, .7]])\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "outputs": [
        {
          "name": "stdout",
          "text": [
            "tensor([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\ntensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "import torch\n\nG.ndata[\u0027feat\u0027] \u003d torch.eye(34)\n\n# print out node 2\u0027s input feature\nprint(G.nodes[2].data[\u0027feat\u0027])\n\n# print out node 10 and 11\u0027s input features\nprint(G.nodes[[10, 11]].data[\u0027feat\u0027])\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "outputs": [],
      "source": "\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# Define the message \u0026 reduce function\n# NOTE: we ignore the GCN\u0027s normalization constant c_ij for this tutorial.\ndef gcn_message(edges):\n    # The argument is a batch of edges.\n    # This computes a (batch of) message called \u0027msg\u0027 using the source node\u0027s feature \u0027h\u0027.\n    return {\u0027msg\u0027 : edges.src[\u0027h\u0027]}\n\ndef gcn_reduce(nodes):\n    # The argument is a batch of nodes.\n    # This computes the new \u0027h\u0027 features by summing received \u0027msg\u0027 in each node\u0027s mailbox.\n    return {\u0027h\u0027 : torch.sum(nodes.mailbox[\u0027msg\u0027], dim\u003d1)}\n\n# Define the GCNLayer module\nclass GCNLayer(nn.Module):\n    def __init__(self, in_feats, out_feats):\n        super(GCNLayer, self).__init__()\n        self.linear \u003d nn.Linear(in_feats, out_feats)\n\n    def forward(self, g, inputs):\n        # g is the graph and the inputs is the input node features\n        # first set the node features\n        g.ndata[\u0027h\u0027] \u003d inputs\n        # trigger message passing on all edges\n        g.send(g.edges(), gcn_message)\n        # trigger aggregation at all nodes\n        g.recv(g.nodes(), gcn_reduce)\n        # get the result node features\n        h \u003d g.ndata.pop(\u0027h\u0027)\n        # perform linear transformation\n        return self.linear(h)\n\n# Define a 2-layer GCN model\nclass GCN(nn.Module):\n    def __init__(self, in_feats, hidden_size, num_classes):\n        super(GCN, self).__init__()\n        self.gcn1 \u003d GCNLayer(in_feats, hidden_size)\n        self.gcn2 \u003d GCNLayer(hidden_size, num_classes)\n\n    def forward(self, g, inputs):\n        h \u003d self.gcn1(g, inputs)\n        h \u003d torch.relu(h)\n        h \u003d self.gcn2(g, h)\n        return h\n# The first layer transforms input features of size of 34 to a hidden size of 5.\n# The second layer transforms the hidden layer and produces output features of\n# size 2, corresponding to the two groups of the karate club.\nnet \u003d GCN(34, 5, 2)\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "outputs": [],
      "source": "\ninputs \u003d torch.eye(34)\nlabeled_nodes \u003d torch.tensor([0, 33])  # only the instructor and the president nodes are labeled\nlabels \u003d torch.tensor([0, 1])  # their labels are different\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "outputs": [
        {
          "name": "stderr",
          "text": [
            "/home/harryzhang/PycharmProjects/gcn_metric_learning/venv/lib/python3.6/site-packages/dgl/base.py:18: UserWarning: Initializer is not set. Use zero initializer instead. To suppress this warning, use `set_initializer` to explicitly specify which initializer to use.\n  warnings.warn(msg)\n"
          ],
          "output_type": "stream"
        },
        {
          "name": "stdout",
          "text": [
            "Epoch 0 | Loss: 2.1390\nEpoch 1 | Loss: 1.3474\nEpoch 2 | Loss: 0.7364\nEpoch 3 | Loss: 0.4126\nEpoch 4 | Loss: 0.2904\nEpoch 5 | Loss: 0.2104\nEpoch 6 | Loss: 0.1404\nEpoch 7 | Loss: 0.0887\nEpoch 8 | Loss: 0.0571\nEpoch 9 | Loss: 0.0391\nEpoch 10 | Loss: 0.0276\nEpoch 11 | Loss: 0.0198\nEpoch 12 | Loss: 0.0144\nEpoch 13 | Loss: 0.0107\nEpoch 14 | Loss: 0.0083\nEpoch 15 | Loss: 0.0066\nEpoch 16 | Loss: 0.0054\nEpoch 17 | Loss: 0.0044\nEpoch 18 | Loss: 0.0038\nEpoch 19 | Loss: 0.0032\nEpoch 20 | Loss: 0.0028\nEpoch 21 | Loss: 0.0025\nEpoch 22 | Loss: 0.0022\nEpoch 23 | Loss: 0.0020\nEpoch 24 | Loss: 0.0018\nEpoch 25 | Loss: 0.0016\nEpoch 26 | Loss: 0.0015\nEpoch 27 | Loss: 0.0013\nEpoch 28 | Loss: 0.0012\nEpoch 29 | Loss: 0.0011\n"
          ],
          "output_type": "stream"
        }
      ],
      "source": "\noptimizer \u003d torch.optim.Adam(net.parameters(), lr\u003d0.01)\nall_logits \u003d []\nfor epoch in range(30):\n    logits \u003d net(G, inputs)\n    # we save the logits for visualization later\n    all_logits.append(logits.detach())\n    logp \u003d F.log_softmax(logits, 1)\n    # we only compute loss for labeled nodes\n    loss \u003d F.nll_loss(logp[labeled_nodes], labels)\n\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()\n\n    print(\u0027Epoch %d | Loss: %.4f\u0027 % (epoch, loss.item()))",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "outputs": [],
      "source": "import matplotlib.animation as animation\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use(\u0027ggplot\u0027)\n\n\n\ndef draw(i):\n    cls1color \u003d \u0027#00FFFF\u0027\n    cls2color \u003d \u0027#FF00FF\u0027\n    pos \u003d {}\n    colors \u003d []\n    for v in range(34):\n        pos[v] \u003d all_logits[i][v].numpy()\n        cls \u003d pos[v].argmax()\n        colors.append(cls1color if cls else cls2color)\n    ax.cla()\n    ax.axis(\u0027off\u0027)\n    ax.set_title(\u0027Epoch: %d\u0027 % i)\n    nx.draw_networkx(nx_G.to_undirected(), pos, node_color\u003dcolors,\n            with_labels\u003dTrue, node_size\u003d300, ax\u003dax)\n\nfig \u003d plt.figure(dpi\u003d150)\nfig.clf()\nax \u003d fig.subplots()\ndraw(0)  # draw the prediction of the first epoch\nplt.close()",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%  \n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "outputs": [],
      "source": "ani \u003d animation.FuncAnimation(fig, draw, frames\u003dlen(all_logits), interval\u003d200)\n\n\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "pycharm-1d4c4257",
      "language": "python",
      "display_name": "PyCharm (gcn_metric_learning)"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}